# -*- coding: utf-8 -*-
"""Sentiment Exploration in 50K IMDb Reviews.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OPmBcH7qdtMkB2cb6Om4Rm6ETECjbENr

# Sentiment Exploration in 50K IMDb Reviews

This notebook explores sentiment analysis on IMDb reviews using various machine learning models. The analysis includes data preprocessing, visualization of the dataset, and the implementation of different classifiers.

## Importing Libraries

Importing necessary libraries for data processing, visualization, and machine learning.
"""

# Import necessary libraries
import nltk
import re
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import matplotlib.style as style
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from wordcloud import WordCloud
from collections import Counter
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split

# Set the matplotlib style to 'ggplot'
style.use('ggplot')

# Download the stopwords and punkt dataset from NLTK
nltk.download('punkt')
nltk.download('stopwords')

# Import NLTK modules for text processing
from nltk.tokenize import word_tokenize
from nltk.stem import PorterStemmer
from nltk.corpus import stopwords

# Set of English stopwords
stop_words = set(stopwords.words('english'))

"""#Loading and Exploring the Dataset
Loading the IMDb dataset, displaying basic information, and performing initial exploratory data analysis.
"""

# Specify the file path for the dataset
file_path = 'IMDB Dataset.csv'

# Read the CSV file into a DataFrame
df = pd.read_csv(file_path)

# Display the DataFrame
print(df)

# Obtain the shape of the DataFrame
df_shape = df.shape

# Display the shape in a formatted way
print(f"The DataFrame has {df_shape[0]} rows and {df_shape[1]} columns.")

# Describe the DataFrame and store the result in a variable
df_summary = df.describe()

# Display the summary statistics
print("Summary Statistics:")
print(df_summary)

# Display information about the DataFrame
print("DataFrame Information:")
df_info = df.info()

"""#Exploratory Data Analysis (EDA)
Visualizing the distribution of sentiments, analyzing word counts, and exploring common words in positive and negative reviews.
"""

# Create a count plot for the 'sentiment' column in the DataFrame
fig = px.histogram(df, x='sentiment', color='sentiment', title="Sentiment Display")

# Show the plot
fig.show()

# Iterate over the first 5 rows of 'review' and 'sentiment' columns using enumerate and zip
for i, (review, sentiment) in enumerate(zip(df['review'].head(5), df['sentiment'].head(5)), start=1):
    # Print the index and review for each iteration
    print(f"Review {i}:")
    print(review, "\n")

    # Print the sentiment for each iteration
    print(f"Sentiment {i}: {sentiment}\n")

# Define a function to count the number of words in a given text
def no_of_words(text):
    words = text.split()
    word_count = len(words)
    return word_count

# Apply the function to the 'review' column and create a new 'Word Count' column
df['Word Count'] = df['review'].apply(no_of_words)

# Display the first few rows of the DataFrame
print("DataFrame Head:")
print(df.head())

import plotly.graph_objects as go
from plotly.subplots import make_subplots

# Assuming 'df' is your DataFrame

# Create a subplot with 1 row and 2 columns
fig = make_subplots(rows=1, cols=2, subplot_titles=('Positive Sentiment', 'Negative Sentiment'))

# Add histograms for positive and negative sentiment with different colors
fig.add_trace(go.Histogram(x=df[df['sentiment']=='positive']['Word Count'], nbinsx=30, marker_color='green'), row=1, col=1)
fig.add_trace(go.Histogram(x=df[df['sentiment']=='negative']['Word Count'], nbinsx=30, marker_color='orange'), row=1, col=2)

# Update layout
fig.update_layout(title_text="Number of Words in Review", showlegend=False)

# Show the plot
fig.show()

# Create a subplot with 1 row and 2 columns
fig = make_subplots(rows=1, cols=2, subplot_titles=('Positive Sentiment', 'Negative Sentiment'))

# Add histograms for positive and negative sentiment with different colors
fig.add_trace(go.Histogram(x=df[df['sentiment']=='positive']['review'].str.len(), nbinsx=30, marker_color='green'), row=1, col=1)
fig.add_trace(go.Histogram(x=df[df['sentiment']=='negative']['review'].str.len(), nbinsx=30, marker_color='orange'), row=1, col=2)

# Update layout
fig.update_layout(title_text="Number of Words in Review", showlegend=False)

# Show the plot
fig.show()

# Use map to replace 'positive' with 1 and 'negative' with 0 in the 'sentiment' column
df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})

df.head()

"""#Data Preprocessing
Cleaning and preprocessing the text data, including converting to lowercase, removing HTML tags, URLs, mentions, hashtags, non-alphanumeric characters, and stopwords.
"""

def data_processing(text):
    # Convert to lowercase
    text = text.lower()

    # Remove HTML tags and URLs
    text = re.sub('<br />|https?\S+|www\S+', '', text, flags=re.MULTILINE)

    # Remove mentions and hashtags
    text = re.sub(r'\@\w+|\#', '', text)

    # Remove non-alphanumeric characters (keeping spaces)
    text = re.sub(r'[^a-zA-Z0-9\s]', '', text)

    # Tokenize the text
    text_tokens = word_tokenize(text)

    # Remove stopwords
    filtered_text = [word for word in text_tokens if word not in stop_words]

    # Join the filtered tokens to form processed text
    return " ".join(filtered_text)

# Apply the data_processing function to the 'review' column
df['review'] = df['review'].apply(lambda x: data_processing(x))

duplicated_count = len(df[df.duplicated()])
print("Number of duplicate entries:", duplicated_count)

df = df.drop_duplicates(subset='review').reset_index(drop=True)

stemmer = PorterStemmer()
def stemming(data):
    text = [stemmer.stem(word) for word in data]
    return data

df.review = df['review'].apply(lambda x: stemming(x))

df['Word Count'] = df['review'].apply(no_of_words)
df.head()

# Extracting positive reviews from the DataFrame where sentiment is equal to 1
positive_reviews = df[df['sentiment'] == 1]

# Displaying the first few rows of positive reviews
positive_reviews_head = positive_reviews.head()

# Printing the result
print(positive_reviews_head)

# Importing a color palette for the pie chart
from palettable.colorbrewer.qualitative import Paired_12

# Assuming positive_reviews is your DataFrame with positive reviews and 'review' column
positive_reviews = df[df['sentiment'] == 1]

# Combine all positive reviews into a single string
positive_text = ' '.join(positive_reviews['review'].tolist())

# Tokenize the words in the positive reviews
words = positive_text.split()

# Count the frequency of each word
word_counts = Counter(words)

# Get the top N most frequent words
top_n_words = 15
top_words = dict(word_counts.most_common(top_n_words))

# Generate a WordCloud for better visualization
wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(top_words)

# Creating a nice color palette
colors = Paired_12.mpl_colors

# Plotting the pie chart with the specified colors
plt.figure(figsize=(10, 10))
plt.pie(top_words.values(), labels=top_words.keys(), autopct='%1.1f%%', startangle=90, wedgeprops=dict(width=0.4), colors=colors)
plt.title('Top {} Most Frequent Words in Positive Reviews'.format(top_n_words), fontsize=16)
plt.axis('equal')  # Equal aspect ratio ensures that the pie is drawn as a circle.
plt.show()

from wordcloud import WordCloud
import matplotlib.pyplot as plt

# Concatenate all the words in positive reviews
text_positive_reviews = ''.join([word for word in positive_reviews['review']])

# Set up the WordCloud parameters
wordcloud_params = {
    'max_words': 500,
    'width': 1600,
    'height': 800,
    'background_color': 'white',  # Add white background color
}

# Generate WordCloud
wordcloud = WordCloud(**wordcloud_params).generate(text_positive_reviews)

# Plotting the WordCloud
plt.figure(figsize=(20, 15), facecolor='None')
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Most Frequent Words in Positive Reviews', fontsize=19)
plt.show()

text_list = positive_reviews['review'].str.split().explode().tolist()
count = Counter()
count.update(text_list)

most_common_words = count.most_common(15)

for word, frequency in most_common_words:
    print(f"{word}: {frequency}")

# Get the 15 most common words and their counts
most_common_words = word_counts.most_common(15)

# Create a DataFrame from the most common words
pos_words_df = pd.DataFrame(most_common_words, columns=['words', 'count'])

# Display the first few rows of the DataFrame
print(pos_words_df.head())

fig = px.bar(pos_words_df, y='words', x='count',
             title='Common Words in Positive Reviews',
             orientation='h', text='count', color='count',
             labels={'count': 'Count'})

# Customize the layout
fig.update_layout(yaxis=dict(categoryorder='total ascending'),
                  xaxis_title='Count', yaxis_title='Words')

# Show the figure
fig.show()

# Extracting negative reviews from the DataFrame where sentiment is equal to 1
negative_reviews = df[df['sentiment'] == 0]

# Displaying the first few rows of negative reviews
negative_reviews_head = negative_reviews.head()

# Printing the result
print(negative_reviews_head)

# Importing a color palette for the pie chart
from palettable.colorbrewer.qualitative import Paired_12

# Assuming positive_reviews is your DataFrame with positive reviews and 'review' column
negative_reviews = df[df['sentiment'] == 0]

# Combine all positive reviews into a single string
negative_text = ' '.join(negative_reviews['review'].tolist())

# Tokenize the words in the positive reviews
words = negative_text.split()

# Count the frequency of each word
word_counts = Counter(words)

# Get the top N most frequent words
top_n_words = 15
top_words = dict(word_counts.most_common(top_n_words))

# Generate a WordCloud for better visualization
wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(top_words)

# Creating a nice color palette
colors = Paired_12.mpl_colors

# Plotting the pie chart with the specified colors
plt.figure(figsize=(10, 10))
plt.pie(top_words.values(), labels=top_words.keys(), autopct='%1.1f%%', startangle=90, wedgeprops=dict(width=0.4), colors=colors)
plt.title('Top {} Most Frequent Words in Positive Reviews'.format(top_n_words), fontsize=16)
plt.axis('equal')  # Equal aspect ratio ensures that the pie is drawn as a circle.
plt.show()

from wordcloud import WordCloud
import matplotlib.pyplot as plt

# Concatenate all the words in positive reviews
text_negative_reviews = ''.join([word for word in negative_reviews['review']])

# Set up the WordCloud parameters
wordcloud_params = {
    'max_words': 500,
    'width': 1600,
    'height': 800,
    'background_color': 'white',  # Add white background color
}

# Generate WordCloud
wordcloud = WordCloud(**wordcloud_params).generate(text_negative_reviews)

# Plotting the WordCloud
plt.figure(figsize=(20, 15), facecolor='None')
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Most Frequent Words in Positive Reviews', fontsize=19)
plt.show()

text_list = negative_reviews['review'].str.split().explode().tolist()
count = Counter()
count.update(text_list)

most_common_words = count.most_common(15)

for word, frequency in most_common_words:
    print(f"{word}: {frequency}")

negative_words = pd.DataFrame(count.most_common(15))
negative_words.columns = ['word','count']
negative_words.head()

# Assuming negative_words is your DataFrame with 'words' and 'count' columns
fig = px.bar(negative_words, y='word', x='count',
             title='Common Words in Negative Reviews',
             orientation='h', text='count', color='count',
             labels={'count': 'Count'})

# Customize the layout
fig.update_layout(yaxis=dict(categoryorder='total ascending'),
                  xaxis_title='Count', yaxis_title='Words')

# Show the figure
fig.show()

"""#Model Training and Evaluation
Training different machine learning models (Logistic Regression, Multinomial Naive Bayes, Linear Support Vector Classifier, Random Forest Classifier, Decision Tree Classifier) and evaluating their performance.
"""

# Extracting the 'review' column and assigning it to the variable X
X = df['review']

# Extracting the 'sentiment' column and assigning it to the variable Y
Y = df['sentiment']

# Initializing a TfidfVectorizer
vect = TfidfVectorizer()

# Using fit_transform to convert the 'review' column into a TF-IDF matrix
X = vect.fit_transform(df['review'])

# Splitting the data into training and testing sets
# test_size=0.3 means 30% of the data will be used for testing, and random_state ensures reproducibility
X_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)

# Assuming X_train, y_train, x_test, y_test are already defined
print(f"Training set size - X_train: {X_train.shape}, y_train: {y_train.shape}")
print(f"Testing set size - x_test: {x_test.shape}, y_test: {y_test.shape}")

# Importing necessary modules from scikit-learn
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import LinearSVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Ignoring warning messages for cleaner output
import warnings
warnings.filterwarnings('ignore')

# Initializing and fitting Logistic Regression model
logistic_regression_model = LogisticRegression()
logistic_regression_model.fit(X_train, y_train)

# Making predictions on the test set
logreg_pred = logistic_regression_model.predict(x_test)

# Calculating and printing test accuracy
logreg_acc = accuracy_score(logreg_pred, y_test)
print(f"Test Accuracy: {logreg_acc*100:.2f}%")

# Confusion matrix
conf_matrix = confusion_matrix(y_test, logreg_pred)
print("Confusion Matrix:")
print(conf_matrix)

# Classification report
class_report = classification_report(y_test, logreg_pred)
print("Classification Report:")
print(class_report)

# Confusion matrix
conf_matrix = confusion_matrix(y_test, logreg_pred)

# Create a heatmap
heatmap = go.Figure(data=go.Heatmap(
                   z=conf_matrix,
                   x=['Predicted Negative', 'Predicted Positive'],
                   y=['Actual Negative', 'Actual Positive'],
                   colorscale='Viridis',
                   showscale=True))

# Customize layout
heatmap.update_layout(title='Confusion Matrix',
                      xaxis_title='Predicted Label',
                      yaxis_title='Actual Label')

# Show the heatmap
heatmap.show()

# Initializing and fitting Multinomial Naive Bayes model
mnb_model = MultinomialNB()
mnb_model.fit(X_train, y_train)

# Making predictions on the test set
mnb_pred = mnb_model.predict(x_test)

# Calculating and printing test accuracy
mnb_acc = accuracy_score(mnb_pred, y_test)
print(f"Test Accuracy: {mnb_acc*100:.2f}%")

# Confusion matrix
conf_matrix_mnb = confusion_matrix(y_test, mnb_pred)
print("Confusion Matrix:")
print(conf_matrix_mnb)

# Classification report
class_report_mnb = classification_report(y_test, mnb_pred)
print("Classification Report:")
print(class_report_mnb)

# Confusion matrix for Multinomial Naive Bayes
conf_matrix_mnb = confusion_matrix(y_test, mnb_pred)

# Create a heatmap
heatmap_mnb = go.Figure(data=go.Heatmap(
                   z=conf_matrix_mnb,
                   x=['Predicted Negative', 'Predicted Positive'],
                   y=['Actual Negative', 'Actual Positive'],
                   colorscale='Viridis',
                   showscale=True))

# Customize layout
heatmap_mnb.update_layout(title='Confusion Matrix - Multinomial Naive Bayes',
                         xaxis_title='Predicted Label',
                         yaxis_title='Actual Label')

# Show the heatmap
heatmap_mnb.show()

# Initializing and fitting Linear Support Vector Classifier (LinearSVC) model
svc_model = LinearSVC()
svc_model.fit(X_train, y_train)

# Making predictions on the test set
svc_pred = svc_model.predict(x_test)

# Calculating and printing test accuracy
svc_acc = accuracy_score(svc_pred, y_test)
print(f"Test Accuracy: {svc_acc*100:.2f}%")

# Confusion matrix
conf_matrix_svc = confusion_matrix(y_test, svc_pred)
print("Confusion Matrix:")
print(conf_matrix_svc)

# Classification report
class_report_svc = classification_report(y_test, svc_pred)
print("Classification Report:")
print(class_report_svc)

# Confusion matrix for LinearSVC
conf_matrix_svc = confusion_matrix(y_test, svc_pred)

# Create a heatmap
heatmap_svc = go.Figure(data=go.Heatmap(
                   z=conf_matrix_svc,
                   x=['Predicted Negative', 'Predicted Positive'],
                   y=['Actual Negative', 'Actual Positive'],
                   colorscale='Viridis',
                   showscale=True))

# Customize layout
heatmap_svc.update_layout(title='Confusion Matrix - LinearSVC',
                          xaxis_title='Predicted Label',
                          yaxis_title='Actual Label')

# Show the heatmap
heatmap_svc.show()

# Initializing and fitting Random Forest Classifier (RandomForestClassifier) model
random_forest_model = RandomForestClassifier()
random_forest_model.fit(X_train, y_train)

# Making predictions on the test set
ranf_pred = random_forest_model.predict(x_test)

# Calculating and printing test accuracy
ranf_acc = accuracy_score(ranf_pred, y_test)
print(f"Test Accuracy: {ranf_acc*100:.2f}%")

# Confusion matrix
conf_matrix_ranf = confusion_matrix(y_test, ranf_pred)
print("Confusion Matrix:")
print(conf_matrix_ranf)

# Classification report
class_report_ranf = classification_report(y_test, ranf_pred)
print("Classification Report:")
print(class_report_ranf)

# Confusion matrix for Random Forest Classifier
conf_matrix_ranf = confusion_matrix(y_test, ranf_pred)

# Create a heatmap
heatmap_ranf = go.Figure(data=go.Heatmap(
                   z=conf_matrix_ranf,
                   x=['Predicted Negative', 'Predicted Positive'],
                   y=['Actual Negative', 'Actual Positive'],
                   colorscale='Viridis',
                   showscale=True))

# Customize layout
heatmap_ranf.update_layout(title='Confusion Matrix - Random Forest Classifier',
                           xaxis_title='Predicted Label',
                           yaxis_title='Actual Label')

# Show the heatmap
heatmap_ranf.show()

# Initializing and fitting Decision Tree Classifier (DecisionTreeClassifier) model
decision_tree_model = DecisionTreeClassifier()
decision_tree_model.fit(X_train, y_train)

# Making predictions on the test set
dt_pred = decision_tree_model.predict(x_test)

# Calculating and printing test accuracy
dt_acc = accuracy_score(dt_pred, y_test)
print(f"Test Accuracy: {dt_acc*100:.2f}%")

# Confusion matrix
conf_matrix_dt = confusion_matrix(y_test, dt_pred)
print("Confusion Matrix:")
print(conf_matrix_dt)

# Classification report
class_report_dt = classification_report(y_test, dt_pred)
print("Classification Report:")
print(class_report_dt)

# Confusion matrix for Decision Tree Classifier
conf_matrix_dt = confusion_matrix(y_test, dt_pred)

# Create a heatmap
heatmap_dt = go.Figure(data=go.Heatmap(
                   z=conf_matrix_dt,
                   x=['Predicted Negative', 'Predicted Positive'],
                   y=['Actual Negative', 'Actual Positive'],
                   colorscale='Viridis',
                   showscale=True))

# Customize layout
heatmap_dt.update_layout(title='Confusion Matrix - Decision Tree Classifier',
                         xaxis_title='Predicted Label',
                         yaxis_title='Actual Label')

# Show the heatmap
heatmap_dt.show()

"""#Model Comparison and Selection
Comparing the accuracy of each model and selecting the best one.
"""

# Print the accuracy of each model
print("Logistic Regression Accuracy:", logreg_acc * 100)
print("Multinomial Naive Bayes Accuracy:", mnb_acc * 100)
print("Linear Support Vector Machine Accuracy:", svc_acc * 100)
print("Random Forest Classifier Accuracy:", ranf_acc * 100)
print("Decision Tree Classifier Accuracy:", dt_acc * 100)

# Find the best model based on accuracy
best_model_accuracy = max(logreg_acc, mnb_acc, svc_acc, ranf_acc, dt_acc)
best_model_name = None

if best_model_accuracy == logreg_acc:
  best_model_name = "Logistic Regression"
elif best_model_accuracy == mnb_acc:
  best_model_name = "Multinomial Naive Bayes"
elif best_model_accuracy == svc_acc:
  best_model_name = "Linear Support Vector Machine"
elif best_model_accuracy == ranf_acc:
  best_model_name = "Random Forest Classifier"
else:
  best_model_name = "Decision Tree Classifier"

# Print the best model name and accuracy
print("\nBest Model:", best_model_name)
print("Best Model Accuracy:", best_model_accuracy * 100)

